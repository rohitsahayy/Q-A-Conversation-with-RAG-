# Q-A-Conversation-with-RAG-
Conversational Q&amp;A with Chat History and RAG

# ğŸ§  Conversational Q&A with Chat History and RAG using LangChain, FAISS, and Streamlit

This project is a **Conversational Retrieval-Augmented Generation (RAG)** system that allows users to ask questions about uploaded PDF documents. It uses **LangChain**, **FAISS**, **Groq LLM**, and **Streamlit** to build an intelligent assistant that supports **multi-turn conversations** with memory.

---

## ğŸš€ Features

- ğŸ“„ Upload multiple PDF documents
- ğŸ’¬ Chat interface with memory (chat history)
- ğŸ” History-aware question rewriting
- ğŸ”— Context-aware document retrieval using FAISS
- ğŸ¤– LLM-generated answers based on retrieved context
- âš¡ Built with LangChain and Groq's `gemma-2b-it` or `gemma-9b-it` models
- ğŸŒ Streamlit frontend for an interactive experience

---

## ğŸ§° Tech Stack

- [LangChain](https://www.langchain.com/)
- [Streamlit](https://streamlit.io/)
- [FAISS](https://github.com/facebookresearch/faiss)
- [Groq LLM API](https://console.groq.com/)
- [Ollama Embeddings](https://ollama.com/)
- [PyPDFLoader](https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf)

