# Q-A-Conversation-with-RAG-
Conversational Q&amp;A with Chat History and RAG

# 🧠 Conversational Q&A with Chat History and RAG using LangChain, FAISS, and Streamlit

This project is a **Conversational Retrieval-Augmented Generation (RAG)** system that allows users to ask questions about uploaded PDF documents. It uses **LangChain**, **FAISS**, **Groq LLM**, and **Streamlit** to build an intelligent assistant that supports **multi-turn conversations** with memory.

---

## 🚀 Features

- 📄 Upload multiple PDF documents
- 💬 Chat interface with memory (chat history)
- 🔍 History-aware question rewriting
- 🔗 Context-aware document retrieval using FAISS
- 🤖 LLM-generated answers based on retrieved context
- ⚡ Built with LangChain and Groq's `gemma-2b-it` or `gemma-9b-it` models
- 🌐 Streamlit frontend for an interactive experience

---

## 🧰 Tech Stack

- [LangChain](https://www.langchain.com/)
- [Streamlit](https://streamlit.io/)
- [FAISS](https://github.com/facebookresearch/faiss)
- [Groq LLM API](https://console.groq.com/)
- [Ollama Embeddings](https://ollama.com/)
- [PyPDFLoader](https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf)

